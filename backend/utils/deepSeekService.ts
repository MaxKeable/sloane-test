import dotenv from "dotenv";
import { io } from "../index";
import Chat from "../models/chat";
import axios from "axios";

dotenv.config();

/**
 * Takes in a prompt, optional base prompt, optional business prompt, and context, and returns a string.
 *
 * @param {string} prompt - The user's input prompt.
 * @param {string} [basePrompt] - The optional base prompt for the assistant.
 * @param {string} [businessPrompt] - The optional business-specific information prompt from the user.
 * @param {any} context - The context for the conversation (chat history).
 * @returns {Promise<string>} - The response text generated by the DeepSeek API.
 */
const deepSeekService = async (
  room: string,
  chatId: string,
  prompt: string,
  context: any,
  basePrompt?: string,
  businessPrompt?: string,
  pdfText?: string,
  imageData?: any,
  model: string = "deepseek-chat",
  memory?: string
) => {
  // Get the chat from the database
  const chat = await Chat.findById(chatId);
  if (!chat) {
    return;
  }

  console.log({ room, chatId, prompt, basePrompt, businessPrompt, context });

  io.on("connection", (socket) => {
    socket.on("joinRoom", (chatId: string) => {
      socket.join(chatId);
      console.log(`User joined room ${chatId}`);
    });
  });

  // Construct the system instruction based on optional prompts
  let systemInstruction = "";

  if (memory) {
    systemInstruction += `${memory}\n\nIMPORTANT: Always refer back to any relevant facts from user memory to personalize your replies, such as names, preferences, goals, or instructions.`;
  }

  if (basePrompt) {
    systemInstruction += `${basePrompt}\n\n`;
  }

  if (businessPrompt) {
    systemInstruction += `Business Background:\n${businessPrompt}\n\nUse this only to inform your answers when relevant. Do not repeat it unless the user asks.\n\n Always respond in a conversational, human tone. Keep answers focused on the user's most recent message. Be clear and helpful without rambling. Keep things concise unless the user asks for detail. Avoid repeating your capabilities or the business background unless requested.\n\nAim to create a friendly back-and-forth flow rather than a long monologue.\n`;
  }

  // Fallback to a generic instruction if no prompts are provided
  if (!basePrompt && !businessPrompt) {
    systemInstruction = "You are a helpful assistant.";
  }
  if (pdfText) {
    prompt =
      `Document Content: ${pdfText}. If the user ask question from the document, please answer based on the document content. \nDocument End\n` +
      prompt;
  }

  systemInstruction += `Previous conversation history:\n${context}\n\nUse this history only to maintain context or continuity. Do not summarise or reference past messages unless the user asks. Keep your response focused on the user's latest message, and keep the tone friendly, clear, and conversational.\n\nFORMATTING: Always format your responses using proper Markdown syntax. Use headers (##, ###), bullet points (-), numbered lists (1.), **bold text**, *italic text*, code blocks (\`\`\`), and other Markdown formatting as appropriate to make your responses well-structured and easy to read.\n`;

  try {
    console.log("Sending request to DeepSeek API...");
    const response = await axios.post(
      "https://api.deepseek.com/v1/chat/completions",
      {
        model: model,
        messages: [
          {
            role: "system",
            content: systemInstruction.trim(),
          },
          {
            role: "user",
            content: prompt,
          },
        ],
        stream: true,
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.DEEPSEEK_API_KEY}`,
          "Content-Type": "application/json",
        },
        responseType: "stream",
      }
    );

    console.log("Received response from DeepSeek API");
    let fullResponse = "";

    response.data.on("data", (chunk: Buffer) => {
      const lines = chunk.toString().split("\n");
      for (const line of lines) {
        if (line.startsWith("data: ")) {
          try {
            const data = JSON.parse(line.slice(6));
            if (data.choices[0].delta.content) {
              const content = data.choices[0].delta.content;
              fullResponse += content;
              console.log("Received chunk from DeepSeek:", content);
              io.to(chatId).emit("openai_response", fullResponse);
            }
          } catch (e) {
            console.error("Error parsing chunk:", e);
            console.error("Problematic chunk:", line);
          }
        }
      }
    });

    response.data.on("end", () => {
      console.log("DeepSeek stream ended. Full response:", fullResponse);
      setTimeout(() => {
        console.log("Closing Stream");
        io.to(chatId).emit("stream_end", fullResponse);

        // Save the chat to the database
        chat.messages.push({
          question: prompt,
          answer: fullResponse,
        });
        chat.save();
      }, 2500);
    });
  } catch (error: any) {
    console.error("Error in DeepSeek API call:", error);
    if (error.response) {
      console.error("DeepSeek API Error Response:", {
        status: error.response.status,
        data: error.response.data,
      });
    }
  }
};

export default deepSeekService;
