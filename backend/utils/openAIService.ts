import OpenAI from "openai";
import dotenv from "dotenv";
import { io } from "../index";
import Chat from "../models/chat";

dotenv.config();

interface ImageData {
  mimeType: string;
  data: string;
}

/**
 * Takes in a prompt, optional base prompt, optional business prompt, and context, and returns a string.
 *
 * @param {string} prompt - The user's input prompt.
 * @param {string} [basePrompt] - The optional base prompt for the assistant.
 * @param {string} [businessPrompt] - The optional business-specific information prompt from the user.
 * @param {any} context - The context for the conversation (chat history).
 * @param {string} [pdfText] - Optional PDF text content.
 * @param {ImageData} [imageData] - Optional image data.
 * @returns {Promise<string>} - The response text generated by the OpenAI chat completions.
 */
const openAIService = async (
  room: string,
  chatId: string,
  prompt: string,
  context: any,
  basePrompt?: string, // Optional parameter
  businessPrompt?: string, // Optional parameter
  pdfText?: string,
  imageData?: ImageData | null,
  memory?: string
) => {
  // Log all incoming parameters for debugging
  console.log("[openAIService] Incoming params:", {
    room,
    chatId,
    prompt,
    context,
    basePrompt,
    businessPrompt,
    pdfText,
    imageData,
  });

  // Get the chat from the database
  const chat = await Chat.findById(chatId);
  if (!chat) {
    console.error("[openAIService] Chat not found for chatId:", chatId);
    return;
  }

  io.on("connection", (socket) => {
    socket.on("joinRoom", (chatId: string) => {
      socket.join(chatId);
      console.log(`User joined room ${chatId}`);
    });
  });

  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY || "",
  });

  // Construct the system message based on optional prompts
  let systemMessage = "";

  if (memory) {
    systemMessage += `${memory}\n\nIMPORTANT: Always refer back to any relevant facts from user memory to personalize your replies, such as names, preferences, goals, or instructions.`;
  }

  if (basePrompt) {
    systemMessage += `${basePrompt}\n\n`;
  }

  if (businessPrompt) {
    systemMessage += `Before we begin, I would like to give you some background on my business: ${businessPrompt}\n\n`;
  }

  // Fallback to a generic system message if no prompts are provided
  if (!basePrompt && !businessPrompt) {
    systemMessage = "You are a helpful assistant.";
  }

  // Add PDF text to the prompt if available
  if (pdfText) {
    prompt =
      `Document Content: ${pdfText}. If the user ask question from the document, please answer based on the document content. \nDocument End\n` +
      prompt;
  }

  systemMessage += `\n\n${context}\n\nIMPORTANT: Use this conversation history ONLY for context and continuity. Focus your response on the user's current message. Keep responses concise and relevant.\n\nFORMATTING: Always format your responses using proper Markdown syntax. Use headers (##, ###), bullet points (-), numbered lists (1.), **bold text**, *italic text*, code blocks (\`\`\`), and other Markdown formatting as appropriate to make your responses well-structured and easy to read.`;

  const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
    {
      role: "system",
      content: systemMessage.trim(), // Remove any leading or trailing whitespace
    },
  ];

  // Log imageData before constructing the user message
  console.log("[openAIService] imageData before OpenAI payload:", imageData);

  // Handle image data if available
  if (imageData) {
    messages.push({
      role: "user",
      content: [
        {
          type: "image_url",
          image_url: {
            url: `data:${imageData.mimeType};base64,${imageData.data}`,
            detail: "high",
          },
        },
        {
          type: "text",
          text: prompt,
        },
      ],
    });
    prompt = "Image Uploaded\n" + prompt;
  } else {
    messages.push({
      role: "user",
      content: prompt,
    });
  }

  // Log the final OpenAI messages payload
  console.log(
    "[openAIService] OpenAI messages payload:",
    JSON.stringify(messages, null, 2)
  );

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4o", // Use gpt-4o for both text and image input
      messages: messages,
      temperature: 1,
      stream: true,
    });

    let response = "";

    for await (const chunk of completion) {
      const content = chunk.choices[0]?.delta?.content || "";
      response += content;

      // Emit each chunk of data as it arrives
      io.to(chatId).emit("openai_response", response);
    }

    // Stream has ended
    setTimeout(() => {
      console.log("Closing Stream");
      // Emit a custom event to signal the end of the stream
      io.to(chatId).emit("stream_end", response); // Send final response if needed

      // Add the response to the database
      chat.messages.push({
        question: prompt,
        answer: response,
      });
      chat.save();
    }, 2500);
  } catch (err: any) {
    console.error(
      "[openAIService] Error from OpenAI:",
      err.response?.data || err.message || err
    );
  }
};

export default openAIService;
